<!DOCTYPE html>

<head>
    <meta charset="utf-8">
    <title> Megha Jain </title>

    <link rel="stylesheet" href="./styles.css"/>
    <link href="https://fonts.googleapis.com/css?family=Montserrat|Roboto" rel="stylesheet">
</head>

<body>
    <div class="container">
	<div class="fit-width">
		<h1>MEGHA JAIN</h1>
	
		<h3 class="animated animated-fade-in has-delay-1 mb-4 mb-md-5">
                    <a class="mr-2" href="/info/">Info</a>
                    <a class="mr-2" href="http://www.linkedin.com/in/megha-jain" target="_blank">LinkedIn</a>
                    <a class="mr-2" href="http://www.github.com/mjain-1" target="_blank">GitHub</a>
                    <a href="mailto:meghaj67@gmail.com">Email</a>
                </h3>
		
		<div class="animated animated-fade-in has-delay-2 mb-4 mb-md-5">
			<h4> Projects </h4>
			<hr class="main mb-3 mb-md-4">
			
			<ul class="project">
				<li class="title-bar">
					<img src="./images/climate_change.png" width="300" height="200">
					<ul class="text">
						<li> Tracking Media Coverage on Climate Change </li>
						<li> <p class="heading"> Tools: </p> <p> scrapy, selenium, pandas, MIT NER, scikit-learn, flask, D3 </p> </li>
						<br>
						<li class="descript"> <p> This project sought to track media coverage on climate change since the 1990s focusing on regional reporting during weather events, specifically droughts, hurricanes, tornadoes, and flooding.
						     Through scraping articles from 12 different news sources, it aimed to answer whether these events are increasingly discussed in the context of climate change, as the science linking climate to the frequency or severity of these events has become more certain,
						     and whether there are any regional differences. The final product is a d3 interactive dashboard. </p> </li>
					</ul>
				</li>
				
				<li class="title-bar">
					<img src="./images/access_art.png" width="300" height="200">
					<ul class="text">
						<li> AccessArt </li>
						<li> <p class="heading"> Tools: </p> <p> scrapy, selenium, pandas, textblob, scikit-learn, flask, SQLite </p> </li>
						<br>
						<li class="descript"> <p> The motivation for this project came from a friend interested in further exploring New York's art scene. Given the lack of publicly accessible feedback on exhibits, I developed a content-based filtering system that
							analyzes exhibit descriptions to make suggestions for similar shows. Using postings from several websites, such as Artbeat and Artsy, the final model implements NLP, specifically NMF, to create a similarity matrix that 
							displays the 3 most similar exhibits given one exhibit. The final results are shown in a flask app. </p> </li>
					</ul>
				</li>
				
				<li class="title-bar">
					<img src="./images/fema-models.png" width="300" height="200">
					<ul class="text">
						<li> Predicting FEMA Declarations </li>
						<li> <p class="heading"> Tools: </p> <p> scikit-learn, pandas, seaborn </p> </li>
						<br>
						<li class="descript"> <p> This project explored classification algorithms through predicting whether a weather event would be declared a disaster. The aim is 
							to help counties better predict disasters and request aid in advance while allowing FEMA to better plan for when they will need to provide aid. This involved 
							using weather data from CDIAC, extreme weather events from the NOAA, and socioeconomic and infrastructure data from the Census and the American Community Survey.
							The final model used is gradient boosting trees, which performed well with 88% recall. </p> </li>
					</ul>
				</li>
				
				<li class="title-bar">
					<img src="./images/fema-models.png" width="300" height="200">
					<ul class="text">
						<li> Predicting FEMA Declarations </li>
						<li> <p class="heading"> Tools: </p> <p> scikit-learn, pandas, seaborn </p> </li>
						<br>
						<li class="descript"> <p> This project explored classification algorithms through predicting whether a weather event would be declared a disaster. The aim is 
							to help counties better predict disasters and request aid in advance while allowing FEMA to better plan for when they will need to provide aid. This involved 
							using weather data from CDIAC, extreme weather events from the NOAA, and socioeconomic and infrastructure data from the Census and the American Community Survey.
							The final model used is gradient boosting trees, which performed well with 88% recall. </p> </li>
					</ul>
				</li>
				
				<li class="title-bar">
					<img src="./images/ugc_eer2.png" width="300" height="200">
					<ul class="text">
						<li> 
							<a class="mr-2" href="http://urbangreencouncil.org/sites/default/files/nyc_energy_water_use_report_2016.pdf" target="_blank"> New York City's Energy and Water Use 2013 Report</a> 
						</li>
						<li> <p class="heading"> Tools: </p> <p> pandas, seaborn </p> </li>
						<br>
						<li class="descript"> <p> Test </p> </li>
					</ul>
				</li>
				
				<li class="title-bar">
					<img src="./images/metered.png" width="300" height="200">
					<ul class="text">
						<li> 
							<a class="mr-2" href="http://metered.urbangreencouncil.org/" target="_blank"> Metered </a>
						</li>
						<li> <p class="heading"> Tools: </p> <p> pandas, seaborn </p> </li>
						<br>
						<li class="descript"> <p> Test </p> </li>
					</ul>
				</li>
			</ul>
	
		</div>
	</div>
	
    </div>
	    
</body>         
